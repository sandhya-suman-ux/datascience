{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-06T05:49:32.412631Z","iopub.execute_input":"2023-07-06T05:49:32.412988Z","iopub.status.idle":"2023-07-06T05:49:32.440551Z","shell.execute_reply.started":"2023-07-06T05:49:32.412906Z","shell.execute_reply":"2023-07-06T05:49:32.439589Z"},"trusted":true,"id":"G0IofwkdBtBm","executionInfo":{"status":"ok","timestamp":1688627252468,"user_tz":-330,"elapsed":496,"user":{"displayName":"Sanju Chinni","userId":"10490266415552518066"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","import pickle\n","import numpy as np\n","from tqdm.notebook import tqdm\n","\n","from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add"],"metadata":{"execution":{"iopub.status.busy":"2023-07-06T05:49:36.691885Z","iopub.execute_input":"2023-07-06T05:49:36.692634Z","iopub.status.idle":"2023-07-06T05:49:43.944856Z","shell.execute_reply.started":"2023-07-06T05:49:36.692595Z","shell.execute_reply":"2023-07-06T05:49:43.943868Z"},"trusted":true,"id":"Cl57bfXABtBn","executionInfo":{"status":"ok","timestamp":1688627337756,"user_tz":-330,"elapsed":4459,"user":{"displayName":"Sanju Chinni","userId":"10490266415552518066"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","from google.colab import drive\n","\n","drive.mount('/content/drive/')\n","\n","zip_ref = zipfile.ZipFile(\"/content/archive (2).zip\", 'r')\n","zip_ref.extractall(\"/tmp\")\n","zip_ref.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"zjN9waLWEfLW","executionInfo":{"status":"error","timestamp":1688628393211,"user_tz":-330,"elapsed":26044,"user":{"displayName":"Sanju Chinni","userId":"10490266415552518066"}},"outputId":"2c942e81-7577-4686-eeb1-56c36f82397e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"error","ename":"BadZipFile","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4a8d31041ac9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/archive (2).zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"]}]},{"cell_type":"code","source":["BASE_DIR = 'https://www.kaggle.com/datasets/adityajn105/flickr8k/download?datasetVersionNumber=1'\n","WORKING_DIR = '/kaggle/working'"],"metadata":{"execution":{"iopub.status.busy":"2023-07-06T05:49:55.357199Z","iopub.execute_input":"2023-07-06T05:49:55.357491Z","iopub.status.idle":"2023-07-06T05:49:55.361774Z","shell.execute_reply.started":"2023-07-06T05:49:55.357458Z","shell.execute_reply":"2023-07-06T05:49:55.360883Z"},"trusted":true,"id":"7Ig6GtqmBtBo","executionInfo":{"status":"ok","timestamp":1688627379640,"user_tz":-330,"elapsed":472,"user":{"displayName":"Sanju Chinni","userId":"10490266415552518066"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# load vgg19 model\n","model = VGG19()\n","# restructure the model\n","model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n","# summarize\n","print(model.summary())"],"metadata":{"execution":{"iopub.status.busy":"2023-07-06T06:28:07.948534Z","iopub.execute_input":"2023-07-06T06:28:07.949713Z","iopub.status.idle":"2023-07-06T06:28:29.079809Z","shell.execute_reply.started":"2023-07-06T06:28:07.949618Z","shell.execute_reply":"2023-07-06T06:28:29.078649Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"f0PAfrAeBtBo","executionInfo":{"status":"ok","timestamp":1688627397465,"user_tz":-330,"elapsed":9982,"user":{"displayName":"Sanju Chinni","userId":"10490266415552518066"}},"outputId":"6cfc5549-13fb-44a8-eb47-5e4d5c74de41"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n","574710816/574710816 [==============================] - 5s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n","=================================================================\n","Total params: 139,570,240\n","Trainable params: 139,570,240\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["# extract features from image\n","features = {}\n","directory = os.path.join(BASE_DIR, 'Images')\n","\n","for img_name in tqdm(os.listdir(directory)):\n","    # load the image from file\n","    img_path = directory + '/' + img_name\n","    image = load_img(img_path, target_size=(224, 224))\n","    # convert image pixels to numpy array\n","    image = img_to_array(image)\n","    # reshape data for model\n","    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","    # preprocess image for vgg\n","    image = preprocess_input(image)\n","    # extract features\n","    feature = model.predict(image, verbose=0)\n","    # get image ID\n","    image_id = img_name.split('.')[0]\n","    # store feature\n","    features[image_id] = feature"],"metadata":{"execution":{"iopub.status.busy":"2022-11-15T08:30:45.42125Z","iopub.execute_input":"2022-11-15T08:30:45.421588Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"0biyVNMpBtBp","executionInfo":{"status":"error","timestamp":1688627403828,"user_tz":-330,"elapsed":495,"user":{"displayName":"Sanju Chinni","userId":"10490266415552518066"}},"outputId":"874eabc4-7ccf-46ed-e06d-73378b833742"},"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-fe101e2d8f50>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# load the image from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.kaggle.com/datasets/adityajn105/flickr8k/download?datasetVersionNumber=1/Images'"]}]},{"cell_type":"code","source":["# store features in pickle\n","pickle.dump(features, open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb'))"],"metadata":{"trusted":true,"id":"CUZj1LUBBtBp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load features from pickle\n","with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:\n","    features = pickle.load(f)"],"metadata":{"trusted":true,"id":"1MqsI11OBtBp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(os.path.join(BASE_DIR, 'captions.txt'), 'r') as f:\n","    next(f)\n","    captions_doc = f.read()"],"metadata":{"trusted":true,"id":"GSS0jHimBtBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create mapping of image to captions\n","mapping = {}\n","# process lines\n","for line in tqdm(captions_doc.split('\\n')):\n","    # split the line by comma(,)\n","    tokens = line.split(',')\n","    if len(line) < 2:\n","        continue\n","    image_id, caption = tokens[0], tokens[1:]\n","    # remove extension from image ID\n","    image_id = image_id.split('.')[0]\n","    # convert caption list to string\n","    caption = \" \".join(caption)\n","    # create list if needed\n","    if image_id not in mapping:\n","        mapping[image_id] = []\n","    # store the caption\n","    mapping[image_id].append(caption)"],"metadata":{"trusted":true,"id":"PPfDbYrDBtBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(mapping)"],"metadata":{"trusted":true,"id":"zth-WAy7BtBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean(mapping):\n","    for key, captions in mapping.items():\n","        for i in range(len(captions)):\n","            # take one caption at a time\n","            caption = captions[i]\n","            # preprocessing steps\n","            # convert to lowercase\n","            caption = caption.lower()\n","            # delete digits, special chars, etc.,\n","            caption = caption.replace('[^A-Za-z]', '')\n","            # delete additional spaces\n","            caption = caption.replace('\\s+', ' ')\n","            # add start and end tags to the caption\n","            caption = 'startseq ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq'\n","            captions[i] = caption"],"metadata":{"trusted":true,"id":"ktAQa06WBtBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# before preprocess of text\n","mapping['1000268201_693b08cb0e']"],"metadata":{"trusted":true,"id":"uyxvxtpBBtBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocess the text\n","clean(mapping)"],"metadata":{"trusted":true,"id":"QOUuL_x6BtBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# after preprocess of text\n","mapping['1000268201_693b08cb0e']"],"metadata":{"trusted":true,"id":"3W7BYLyUBtBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_captions = []\n","for key in mapping:\n","    for caption in mapping[key]:\n","        all_captions.append(caption)"],"metadata":{"trusted":true,"id":"_WdpZPYbBtBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(all_captions)"],"metadata":{"trusted":true,"id":"KnJOj2SbBtBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_captions[:10]"],"metadata":{"trusted":true,"id":"9u6oE0WbBtBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(all_captions)\n","vocab_size = len(tokenizer.word_index) + 1"],"metadata":{"trusted":true,"id":"TWpLlvKPBtBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size"],"metadata":{"trusted":true,"id":"cqGXvzrsBtBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get maximum length of the caption available\n","max_length = max(len(caption.split()) for caption in all_captions)\n","max_length"],"metadata":{"trusted":true,"id":"nrUjQMiVBtBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_ids = list(mapping.keys())\n","split = int(len(image_ids) * 0.90)\n","train = image_ids[:split]\n","test = image_ids[split:]"],"metadata":{"trusted":true,"id":"4NIA-gaEBtBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create data generator to get data in batch (avoids session crash)\n","def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n","    # loop over images\n","    X1, X2, y = list(), list(), list()\n","    n = 0\n","    while 1:\n","        for key in data_keys:\n","            n += 1\n","            captions = mapping[key]\n","            # process each caption\n","            for caption in captions:\n","                # encode the sequence\n","                seq = tokenizer.texts_to_sequences([caption])[0]\n","                # split the sequence into X, y pairs\n","                for i in range(1, len(seq)):\n","                    # split into input and output pairs\n","                    in_seq, out_seq = seq[:i], seq[i]\n","                    # pad input sequence\n","                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","                    # encode output sequence\n","                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","\n","                    # store the sequences\n","                    X1.append(features[key][0])\n","                    X2.append(in_seq)\n","                    y.append(out_seq)\n","            if n == batch_size:\n","                X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n","                yield [X1, X2], y\n","                X1, X2, y = list(), list(), list()\n","                n = 0"],"metadata":{"trusted":true,"id":"fcQ1--F6BtBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# encoder model\n","# image feature layers\n","inputs1 = Input(shape=(4096,))\n","fe1 = Dropout(0.4)(inputs1)\n","fe2 = Dense(256, activation='relu')(fe1)\n","# sequence feature layers\n","inputs2 = Input(shape=(max_length,))\n","se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","se2 = Dropout(0.4)(se1)\n","se3 = LSTM(256)(se2)\n","\n","# decoder model\n","decoder1 = add([fe2, se3])\n","decoder2 = Dense(256, activation='relu')(decoder1)\n","outputs = Dense(vocab_size, activation='softmax')(decoder2)\n","\n","model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","# plot the model\n","plot_model(model, show_shapes=True)"],"metadata":{"trusted":true,"id":"qMvS8THrBtBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train the model\n","epochs = 10\n","batch_size = 32\n","steps = len(train) // batch_size\n","\n","for i in range(epochs):\n","    # create data generator\n","    generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n","    # fit for one epoch\n","    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)"],"metadata":{"trusted":true,"id":"qL2QdziEBtBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save the model\n","model.save(WORKING_DIR+'/best_model.h5')"],"metadata":{"trusted":true,"id":"jqpA3IK5BtBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def idx_to_word(integer, tokenizer):\n","    for word, index in tokenizer.word_index.items():\n","        if index == integer:\n","            return word\n","    return None"],"metadata":{"trusted":true,"id":"SlZDbZnfBtBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate caption for an image\n","def predict_caption(model, image, tokenizer, max_length):\n","    # add start tag for generation process\n","    in_text = 'startseq'\n","    # iterate over the max length of sequence\n","    for i in range(max_length):\n","        # encode input sequence\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        # pad the sequence\n","        sequence = pad_sequences([sequence], max_length)\n","        # predict next word\n","        yhat = model.predict([image, sequence], verbose=0)\n","        # get index with high probability\n","        yhat = np.argmax(yhat)\n","        # convert index to word\n","        word = idx_to_word(yhat, tokenizer)\n","        # stop if word not found\n","        if word is None:\n","            break\n","        # append word as input for generating next word\n","        in_text += \" \" + word\n","        # stop if we reach end tag\n","        if word == 'endseq':\n","            break\n","\n","    return in_text"],"metadata":{"trusted":true,"id":"LTDfzvcmBtBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.translate.bleu_score import corpus_bleu\n","# validate with test data\n","actual, predicted = list(), list()\n","\n","for key in tqdm(test):\n","    # get actual caption\n","    captions = mapping[key]\n","    # predict the caption for image\n","    y_pred = predict_caption(model, features[key], tokenizer, max_length)\n","    # split into words\n","    actual_captions = [caption.split() for caption in captions]\n","    y_pred = y_pred.split()\n","    # append to the list\n","    actual.append(actual_captions)\n","    predicted.append(y_pred)\n","\n","# calcuate BLEU score\n","print(\"BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n","print(\"BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))"],"metadata":{"trusted":true,"id":"GLJARUK7BtBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","def generate_caption(image_name):\n","    # load the image\n","    # image_name = \"1001773457_577c3a7d70.jpg\"\n","    image_id = image_name.split('.')[0]\n","    img_path = os.path.join(BASE_DIR, \"Images\", image_name)\n","    image = Image.open(img_path)\n","    captions = mapping[image_id]\n","    print('---------------------Actual---------------------')\n","    for caption in captions:\n","        print(caption)\n","    # predict the caption\n","    y_pred = predict_caption(model, features[image_id], tokenizer, max_length)\n","    print('--------------------Predicted--------------------')\n","    print(y_pred)\n","    plt.imshow(image)"],"metadata":{"trusted":true,"id":"wyK4bZp7BtBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_caption(\"1022454332_6af2c1449a.jpg\")"],"metadata":{"trusted":true,"id":"HGcuTYqIBtBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IwlMEU3PBtBu"},"execution_count":null,"outputs":[]}]}